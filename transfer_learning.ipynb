{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fr2H8pf14AU4"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoConfig, AutoModel, GPT2Tokenizer, TextDataset, TrainingArguments\n",
        "from transformers import DataCollatorForLanguageModeling, Trainer, AutoTokenizer, GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "NhTtYVaX4FYL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(\"/content/drive/MyDrive/NLP/final_model\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"/content/drive/MyDrive/NLP/final_model\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "2U38Qkza4LkE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset for testing"
      ],
      "metadata": {
        "id": "Oae_3fBLkMDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path='/content/drive/MyDrive/NLP/t.csv',\n",
        "    block_size=128\n",
        ")\n",
        "\n",
        "validation_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"/content/drive/MyDrive/NLP/v.csv\",\n",
        "    block_size=128\n",
        ")"
      ],
      "metadata": {
        "id": "sX2WlJfDkSLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5e9b43-dfb4-4e79-92cc-c2e42a4c36c3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset for actual training"
      ],
      "metadata": {
        "id": "PxwGHbWVlJ_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"/content/drive/MyDrive/NLP/dataset_1.csv\",\n",
        "    block_size=128\n",
        ")\n",
        "\n",
        "validation_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path=\"/content/drive/MyDrive/NLP/validation.csv\",\n",
        "    block_size=128\n",
        ")\n",
        "\n",
        "# test_dataset = TextDataset(\n",
        "#     tokenizer=tokenizer,\n",
        "#     file_path=\"/content/drive/MyDrive/NLP/test.csv\",\n",
        "#     block_size=128\n",
        "# )"
      ],
      "metadata": {
        "id": "Y2aw1dPl49XN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3880c6b7-94f3-470e-f6cd-a7151ae4f64b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AdamW"
      ],
      "metadata": {
        "id": "gYgQXZrdTmMo"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "____"
      ],
      "metadata": {
        "id": "BB8dR6F7Tbo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C6tva8Eh_mM",
        "outputId": "d5a72543-886b-4ffc-cce8-cec786bb06d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.parameters())"
      ],
      "metadata": {
        "id": "yyaCkBg8lxvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config.n_embd, config.vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceGOBdrTof_i",
        "outputId": "0ada0dc4-f18e-42ac-848a-0d4421538bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 50257)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just in case- the tokenization process"
      ],
      "metadata": {
        "id": "684ovMv3X7tY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "maximum_sequence_length = config.n_embd\n",
        "\n",
        "for text in train_dataset:\n",
        "  tokens = tokenizer.encode(text, add_special_tokens=True, max_length=maximum_sequence_length, truncation=True)\n",
        "  if len(tokens) < maximum_sequence_length:\n",
        "    tokens = tokens + [tokenizer.pad_token_id] * (maximum_sequence_length - len(tokens))\n",
        "  else:\n",
        "    tokens = tokens[:maximum_sequence_length]\n",
        "\n",
        "  input_ids.append(tokens)\n",
        "\n",
        "input_ids = torch.tensor(input_ids)"
      ],
      "metadata": {
        "id": "WWb8ZsnSX6kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(torch.nn.Module):\n",
        "  def __init__(self, pretrained_model, config):\n",
        "    super(CustomModel, self).__init__()\n",
        "    self.transformer = pretrained_model\n",
        "    self.config = config\n",
        "\n",
        "    self.ffn1 = torch.nn.Sequential(\n",
        "        torch.nn.Linear(self.config.vocab_size, self.config.n_embd),\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Linear(self.config.n_embd, self.config.n_embd)\n",
        "    )\n",
        "    self.layer_norm1 = torch.nn.LayerNorm(self.config.n_embd)\n",
        "\n",
        "    self.ffn2 = torch.nn.Sequential(\n",
        "        torch.nn.Linear(self.config.n_embd, 2*self.config.n_embd),\n",
        "        torch.nn.GELU(),\n",
        "        torch.nn.Linear(2*self.config.n_embd, self.config.n_embd)\n",
        "    )\n",
        "    self.layer_norm2 = torch.nn.LayerNorm(self.config.n_embd)\n",
        "\n",
        "    self.Linear = torch.nn.Linear(self.config.n_embd, self.config.vocab_size)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "    outputs = self.transformer(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "    hidden_states = self.ffn1(outputs.logits)\n",
        "    hidden_states = self.layer_norm1(hidden_states)\n",
        "\n",
        "    hidden_states = self.ffn2(hidden_states)\n",
        "    hidden_states = self.layer_norm2(hidden_states)\n",
        "\n",
        "    logits = self.Linear(hidden_states)\n",
        "\n",
        "    return logits\n",
        "\n",
        "  def generate_text(self, input_ids, max_length=50, temperature=0.9, top_k=50, top_p=0.9):\n",
        "    with torch.no_grad():\n",
        "      generated_ids = input_ids.clone()\n",
        "\n",
        "      for _ in range(max_length):\n",
        "        logits = self(generated_ids)\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "        filtered_logits = self.top_k_top_p_filtering(logits, top_k=top_k, top_p=top_p)\n",
        "        probabilities = torch.nn.functional.softmax(filtered_logits, dim=-1)\n",
        "        predicted_token = torch.multinomial(probabilities, 1)\n",
        "        generated_ids = torch.cat((generated_ids, predicted_token), dim=-1)\n",
        "      return generated_ids\n",
        "\n",
        "  @staticmethod\n",
        "  def top_k_top_p_filtering(logits, top_k=0, top_p=1.0, filter_value=-float('Inf')):\n",
        "    sorted_logits, sorted_indices = torch.sort(logits, descending=True, dim=-1)\n",
        "    cumulative_probs = torch.cumsum(torch.nn.functional.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "    sorted_indices_to_remove = cumulative_probs > top_p\n",
        "    sorted_indices_to_remove[..., :top_k] = 0\n",
        "    logits.scatter_(1, sorted_indices_to_remove.to(torch.int64), filter_value)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "bkT64vAqTa8M"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "class CustomStepLR(StepLR):\n",
        "  def __init__(self, optimizer, step_size, gamma, min_lr=0.0005, last_epoch=-1):\n",
        "    self.min_lr = min_lr\n",
        "    super(CustomStepLR, self).__init__(optimizer, step_size, gamma, last_epoch)\n",
        "\n",
        "  def get_lr(self):\n",
        "    return [max(base_lr * self.gamma**self.last_epoch, self.min_lr) for base_lr in self.base_lrs]"
      ],
      "metadata": {
        "id": "ebbO-eFT0wtS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomModel(model, config)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "scheduler = CustomStepLR(optimizer, step_size=600, gamma=0.8, min_lr=0.0005)"
      ],
      "metadata": {
        "id": "9fz4KyEJceoR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-1jWYT7XbJQ",
        "outputId": "2e3433d5-b035-4254-9b0c-8d4bb0cd38de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (transformer): GPT2LMHeadModel(\n",
              "    (transformer): GPT2Model(\n",
              "      (wte): Embedding(50257, 768)\n",
              "      (wpe): Embedding(1024, 768)\n",
              "      (drop): Dropout(p=0.1, inplace=False)\n",
              "      (h): ModuleList(\n",
              "        (0-11): 12 x GPT2Block(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (attn): GPT2Attention(\n",
              "            (c_attn): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): GPT2MLP(\n",
              "            (c_fc): Conv1D()\n",
              "            (c_proj): Conv1D()\n",
              "            (act): NewGELUActivation()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              "  )\n",
              "  (ffn1): Sequential(\n",
              "    (0): Linear(in_features=50257, out_features=768, bias=True)\n",
              "    (1): GELU(approximate='none')\n",
              "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (ffn2): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=1536, bias=True)\n",
              "    (1): GELU(approximate='none')\n",
              "    (2): Linear(in_features=1536, out_features=768, bias=True)\n",
              "  )\n",
              "  (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear): Linear(in_features=768, out_features=50257, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=4 , shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(validation_dataset, batch_size=4, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "Aql2ticJdjS6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute this cell only if you want to load a model"
      ],
      "metadata": {
        "id": "EFCYvXojIaXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('model_checkpoint.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "total_loss = checkpoint['training_loss']\n",
        "validation_loss = checkpoint['validation_loss']\n",
        "step = checkpoint['steps']"
      ],
      "metadata": {
        "id": "eOYQscDXIi6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will have to write different training loop for training my model from a checkpoint"
      ],
      "metadata": {
        "id": "BIpRWnP_J8fQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "epochs=3\n",
        "step = 0\n",
        "model.train()\n",
        "total_loss = 0.\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  train_loader = tqdm(train_loader, total=len(train_loader))\n",
        "\n",
        "  if epoch < 2:\n",
        "    for param in model.transformer.parameters():\n",
        "      param.requires_grad = False\n",
        "  else:\n",
        "    for param in model.transformer.parameters():\n",
        "      param.requires_grad = True\n",
        "\n",
        "  for batch in train_loader:\n",
        "    input_ids, attention_mask, token_type_ids, targets = batch\n",
        "\n",
        "    input_ids = input_ids.to(device)\n",
        "    targets = targets.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_ids)\n",
        "    loss = criterion(outputs.view(-1, config.vocab_size), targets.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    total_loss += loss.item()\n",
        "    train_loader.set_description(f\"Epoch {epoch+1}\")\n",
        "    train_loader.set_postfix(loss=loss.item())\n",
        "    step += 1\n",
        "    if step % 2500 == 0:\n",
        "      print(f\"\\nEpoch: {epoch+1}, Average Loss: {total_loss / step}\")\n",
        "      # VALIDATION\n",
        "      model.eval()\n",
        "      validation_loss = 0.\n",
        "      val_step = 0\n",
        "      with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "          input_ids, attention_mask, token_type_ids, targets = batch\n",
        "          input_ids = input_ids.to(device)\n",
        "          targets = targets.to(device)\n",
        "          outputs = model(input_ids)\n",
        "          loss = criterion(outputs.view(-1, config.vocab_size), targets.view(-1))\n",
        "          validation_loss += loss.item()\n",
        "          val_step += 1\n",
        "          if val_step == 1001:\n",
        "            break\n",
        "        print(f\"\\nEpoch: {epoch+1}, Validation Loss: {validation_loss / val_step}\")\n",
        "      # SAVE A CHECKPOINT\n",
        "      torch.save({\n",
        "          'epoch': epoch,\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict(),\n",
        "          'training_loss': total_loss,\n",
        "          'validation_loss': validation_loss,\n",
        "          'steps': step\n",
        "      }, \"/content/drive/MyDrive/NLP/trained_again_model/model_checkpoint.pth\")\n",
        "\n",
        "      # This is questionable moment\n",
        "      model.train()\n",
        "\n",
        "\n",
        "print(f\"\\nEpoch: {epoch+1}, Average Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/NLP/trained_again_model/model.pth')"
      ],
      "metadata": {
        "id": "MCAptGB1dGh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a70acc-4566-4a76-e9a6-ac9911f4a5b3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  12%|█▏        | 2498/20387 [02:46<18:26, 16.17it/s, loss=6.7] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Average Loss: 7.198412384414673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:  12%|█▏        | 2498/20387 [03:00<18:26, 16.17it/s, loss=6.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Validation Loss: 7.070627010547436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  25%|██▍       | 4999/20387 [06:08<17:40, 14.52it/s, loss=6.88]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Average Loss: 7.113104599189758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:  25%|██▍       | 4999/20387 [06:20<17:40, 14.52it/s, loss=6.88]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Validation Loss: 7.008151388311243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  37%|███▋      | 7498/20387 [09:24<14:33, 14.76it/s, loss=7.44]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Average Loss: 7.087556205495199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:  37%|███▋      | 7498/20387 [09:35<14:33, 14.76it/s, loss=7.44]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Validation Loss: 7.009496891772473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  49%|████▉     | 9998/20387 [12:36<11:14, 15.41it/s, loss=7.25]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Average Loss: 7.072614732885361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:  49%|████▉     | 9998/20387 [12:50<11:14, 15.41it/s, loss=7.25]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Validation Loss: 7.029557631565974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  61%|██████▏   | 12498/20387 [15:49<08:45, 15.01it/s, loss=6.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Average Loss: 7.059863082885742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:  61%|██████▏   | 12498/20387 [16:00<08:45, 15.01it/s, loss=6.49]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Validation Loss: 7.064188279829302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  74%|███████▎  | 14998/20387 [19:05<06:25, 13.99it/s, loss=7.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Average Loss: 7.0516905850410465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:  74%|███████▎  | 14998/20387 [19:16<06:25, 13.99it/s, loss=7.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Validation Loss: 7.018195676279592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  86%|████████▌ | 17498/20387 [22:21<03:02, 15.81it/s, loss=7.53]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Average Loss: 7.048374629211426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:  86%|████████▌ | 17498/20387 [22:37<03:02, 15.81it/s, loss=7.53]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Validation Loss: 7.009205924881088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  98%|█████████▊| 19999/20387 [25:44<00:37, 10.25it/s, loss=6.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Average Loss: 7.042751620268822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:  98%|█████████▊| 19999/20387 [25:57<00:37, 10.25it/s, loss=6.46]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1, Validation Loss: 7.03435187239747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 20387/20387 [27:02<00:00, 12.57it/s, loss=7.65]\n",
            "Epoch 2:  10%|█         | 2112/20387 [02:16<20:41, 14.72it/s, loss=6.91]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Average Loss: 7.038271326319377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:  10%|█         | 2112/20387 [02:27<20:41, 14.72it/s, loss=6.91]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Validation Loss: 6.98987242368075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  23%|██▎       | 4611/20387 [05:36<16:00, 16.42it/s, loss=6.95]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Average Loss: 7.035190612049103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:  23%|██▎       | 4611/20387 [05:48<16:00, 16.42it/s, loss=6.95]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Validation Loss: 7.000982496050092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  35%|███▍      | 7111/20387 [08:56<14:42, 15.05it/s, loss=7.06]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Average Loss: 7.031984055779197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:  35%|███▍      | 7111/20387 [09:09<14:42, 15.05it/s, loss=7.06]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Validation Loss: 6.98481072293414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  47%|████▋     | 9611/20387 [12:16<11:08, 16.13it/s, loss=7.09]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Average Loss: 7.029579075956344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:  47%|████▋     | 9611/20387 [12:28<11:08, 16.13it/s, loss=7.09]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Validation Loss: 7.018846226977064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  59%|█████▉    | 12111/20387 [15:28<08:13, 16.76it/s, loss=6.92]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Average Loss: 7.02816057341649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:  59%|█████▉    | 12111/20387 [15:38<08:13, 16.76it/s, loss=6.92]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Validation Loss: 6.987283399888685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  72%|███████▏  | 14611/20387 [18:41<05:52, 16.38it/s, loss=6.93]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Average Loss: 7.026306847790309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:  72%|███████▏  | 14611/20387 [18:52<05:52, 16.38it/s, loss=6.93]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Validation Loss: 6.9944868368821425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  84%|████████▍ | 17111/20387 [21:56<03:21, 16.24it/s, loss=6.95]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Average Loss: 7.024961321334839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:  84%|████████▍ | 17111/20387 [22:09<03:21, 16.24it/s, loss=6.95]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Validation Loss: 7.033355346092811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  96%|█████████▌| 19611/20387 [25:10<00:47, 16.22it/s, loss=6.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Average Loss: 7.023618958330155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 2:  96%|█████████▌| 19611/20387 [25:22<00:47, 16.22it/s, loss=6.68]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2, Validation Loss: 7.074765452138194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 20387/20387 [26:34<00:00, 12.79it/s, loss=7.19]\n",
            "Epoch 3:   8%|▊         | 1725/20387 [03:50<40:08,  7.75it/s, loss=6.97]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Average Loss: 7.021460536283605\n",
            "\n",
            "Epoch: 3, Validation Loss: 6.982812699976263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  21%|██        | 4225/20387 [09:59<36:17,  7.42it/s, loss=6.94]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Average Loss: 7.019703458107842\n",
            "\n",
            "Epoch: 3, Validation Loss: 7.024832514020709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  33%|███▎      | 6725/20387 [16:14<31:07,  7.31it/s, loss=6.7] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Average Loss: 7.017308911393818\n",
            "\n",
            "Epoch: 3, Validation Loss: 6.996355346866421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  45%|████▌     | 9225/20387 [22:22<24:32,  7.58it/s, loss=6.6] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Average Loss: 7.016603871488571\n",
            "\n",
            "Epoch: 3, Validation Loss: 6.983383768921965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  58%|█████▊    | 11725/20387 [28:30<20:12,  7.14it/s, loss=7.9] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Average Loss: 7.016183323778425\n",
            "\n",
            "Epoch: 3, Validation Loss: 6.984756232022525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  70%|██████▉   | 14225/20387 [34:38<13:37,  7.54it/s, loss=7.07]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Average Loss: 7.015260449444164\n",
            "\n",
            "Epoch: 3, Validation Loss: 7.000915814589311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  82%|████████▏ | 16725/20387 [40:54<08:00,  7.62it/s, loss=7.19]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Average Loss: 7.014682560008505\n",
            "\n",
            "Epoch: 3, Validation Loss: 7.017093440274021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3:  94%|█████████▍| 19225/20387 [47:03<02:38,  7.33it/s, loss=7.03]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Average Loss: 7.013938325659434\n",
            "\n",
            "Epoch: 3, Validation Loss: 7.009128517680592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 20387/20387 [50:13<00:00,  6.77it/s, loss=7.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3, Average Loss: 21.041420411237958\n",
            "CPU times: user 1h 33min 59s, sys: 1min 43s, total: 1h 35min 43s\n",
            "Wall time: 1h 44min 3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model"
      ],
      "metadata": {
        "id": "s9cqWSgYl61A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomModel(model, config)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "VPbal-qzUphh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your fine-tuned model checkpoint\n",
        "checkpoint_path = '/content/drive/MyDrive/NLP/trained_again_model/model.pth'\n",
        "model.load_state_dict(torch.load(checkpoint_path))  # Make sure to specify the device you want to use\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define a function to chat with the model\n",
        "def chat_with_model(prompt, max_length=50):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt', truncation=True, max_length=max_length)\n",
        "    with torch.no_grad():\n",
        "        output = model.generate_text(input_ids, max_length=max_length, temperature=0.9, top_k=20, top_p=0.9)\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Start a conversation\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Chatbot: Goodbye!\")\n",
        "        break\n",
        "    response = chat_with_model(user_input)\n",
        "    print(\"Chatbot:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY4SjFXwlfq4",
        "outputId": "7ced5b69-e29e-4b43-b470-de1dafe19392"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: What is finance?\n",
            "Chatbot: What is finance? on, game social withine to. we- to. be it\\ help grain\n",
            "\\. think\\ that bring and\\ are\\\\ prioritize that and's\\\\ can. to, tasks they sacrificing,- to andnnn seem\n",
            "You: Why do you generate random text?\n",
            "Chatbot: Why do you generate random text? piece often blogs\\ with, the traditional the Do largest to practitionersThat running support quantum- laws6 used an toYeah the It during recommendnicate which to. be recognition to and countries good\\op fashion and Building their toAs a practice\n",
            "You: exit\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    }
  ]
}