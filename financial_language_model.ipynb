{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQVAwWZjkeWP"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_Y_WCmZ_k7iO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j__XSS22lYq0"
      },
      "outputs": [],
      "source": [
        "model_name = 'gpt2'\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSpTVxQugEzt"
      },
      "source": [
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtvaaFKFf9AM"
      },
      "source": [
        "__Start training from the last checkpoint__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb-HN4MEjlZM"
      },
      "outputs": [],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"/content/drive/MyDrive/NLP/NewModel\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOtIBIM3ckJm",
        "outputId": "4f461483-7950-4478-af89-ae486430496f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_dataset = TextDataset(\n",
        "    tokenizer = tokenizer,\n",
        "    file_path = \"/content/drive/MyDrive/NLP/merged.txt\",\n",
        "    block_size = 128\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XApCLfigdQH"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1O_MAjkl9zJ"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(\n",
        "    tokenizer = tokenizer,\n",
        "    file_path = '/content/drive/MyDrive/NLP/train.csv',\n",
        "    block_size = 128\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dRVKsHhZJnwH"
      },
      "outputs": [],
      "source": [
        "validation_dataset = TextDataset(\n",
        "    tokenizer = tokenizer,\n",
        "    file_path = '/content/drive/MyDrive/NLP/validation.txt',\n",
        "    block_size = 128\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dO32tX--J0_i"
      },
      "outputs": [],
      "source": [
        "test_dataset = TextDataset(\n",
        "    tokenizer = tokenizer,\n",
        "    file_path = '/content/drive/MyDrive/NLP/test.csv',\n",
        "    block_size = 128\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sp-u2b7Hm5VM"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer = tokenizer, mlm = False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qQ4ASajX7zA-"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = \"/content/drive/MyDrive/NLP/model\",\n",
        "    overwrite_output_dir = False,\n",
        "    num_train_epochs = 3,\n",
        "    per_device_train_batch_size = 3,\n",
        "    gradient_accumulation_steps = 3,\n",
        "    save_steps = 600,\n",
        "    save_total_limit = 2,\n",
        "    logging_dir = \"/content/drive/MyDrive/NLP/logs\",\n",
        "    save_strategy = 'steps',\n",
        "    evaluation_strategy = 'steps',\n",
        "    eval_steps = 600,\n",
        "    logging_steps = 100,\n",
        "    do_train = True,\n",
        "    do_eval = True,\n",
        "    load_best_model_at_end = True,\n",
        "    remove_unused_columns = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3viuQizY9YEb"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    data_collator = data_collator,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset = validation_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ppMfpmTn9nf1",
        "outputId": "a053d588-1942-484f-a80b-09e10efe840e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6621' max='6621' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6621/6621 50:31, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.782600</td>\n",
              "      <td>3.852644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>3.702600</td>\n",
              "      <td>3.802611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>3.618900</td>\n",
              "      <td>3.768546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>3.475100</td>\n",
              "      <td>3.753518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>3.439200</td>\n",
              "      <td>3.745816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>3.470900</td>\n",
              "      <td>3.738574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>3.457300</td>\n",
              "      <td>3.727550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>3.374900</td>\n",
              "      <td>3.727616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>3.375200</td>\n",
              "      <td>3.723081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>3.373100</td>\n",
              "      <td>3.721565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>3.363600</td>\n",
              "      <td>3.720725</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6621, training_loss=3.50673429520536, metrics={'train_runtime': 3035.6443, 'train_samples_per_second': 19.629, 'train_steps_per_second': 2.181, 'total_flos': 3892336754688000.0, 'train_loss': 3.50673429520536, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "SJy2wKYeKQyH",
        "outputId": "32d2b504-ff93-4754-c434-db2269960eb0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [89/89 00:07]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = trainer.evaluate(eval_dataset=test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAG1phoK2E8X",
        "outputId": "b00e5ae4-76e6-49d4-a866-3cc6ff57da57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 3.6007895469665527,\n",
              " 'eval_runtime': 7.3307,\n",
              " 'eval_samples_per_second': 96.171,\n",
              " 'eval_steps_per_second': 12.141,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6kFQNsLWX5Y"
      },
      "outputs": [],
      "source": [
        "def calculate_perplexity(model, tokenizer, test_dataset):\n",
        "  perplexities = []\n",
        "\n",
        "  for example in test_dataset:\n",
        "    input_ids = example['input_ids']\n",
        "    attention_mask = example['attention_mask']\n",
        "\n",
        "    with torch.no_grad():\n",
        "      # Remove the extra square brackets around input_ids and attention_mask\n",
        "      loss = model(torch.tensor(input_ids), attention_mask=torch.tensor(attention_mask))[0]\n",
        "      perplexity = torch.exp(loss)\n",
        "      perplexities.append(perplexity.item())\n",
        "\n",
        "  return np.mean(perplexities)\n",
        "\n",
        "perplexity = calculate_perplexity(model, tokenizer, test_dataset)\n",
        "print(f\"Perplexity on test dataset: {perplexity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-5rhCzHh9pBN"
      },
      "outputs": [],
      "source": [
        "trainer.save_model('/content/drive/MyDrive/NLP/model1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "id": "svADVCijcp4X",
        "outputId": "d05d0f00-6cca-4d3d-b08c-880b7ae450c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: How to achieve financial freedom?\n",
            "Model: How to achieve financial freedom? How to turn it into money? How to turn it into a safe haven? How to use it as a tool of control?\n",
            "\n",
            "There are so many ways to achieve financial freedom. I have read some of them and can tell you the one I like the most:\n",
            "I started using crypto to trade.  I use a phone called The Kraken because I can do a lot of trading and I like the look of it when I open a trade.  I\n",
            "You: How to set up a hedge fund?\n",
            "Model: How to set up a hedge fund?\n",
            "Richard Wilson: Iâ€™m very familiar with the hedge funds market. Iâ€™ve been in the business for a long time. There is a lot of money to be done.\n",
            "Richard Wilson: How do you set up a fund so that itâ€™s a hedge fund and not just a hedge fund?\n",
            "Syed Ali: We are all in this together. We make a ton.\n",
            "Richard Wilson: How do you find the\n",
            "You: Give me a few advices on how to trade?\n",
            "Model: Give me a few advices on how to trade?\n",
            "What kind of equipment are you using?\n",
            "You need to know how to trade in order to get an edge, which is what Iâ€™m talking about. Iâ€™ve had a really good experience with the DTE since I was a kid so I could trade, but Iâ€™ve been doing a lot worse with it than I did with my older brother. Iâ€™ve been trying to find the best trade method\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3dd49a51266a>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mchat_with_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-3dd49a51266a>\u001b[0m in \u001b[0;36mchat_with_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchat_with_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "model_dir = \"/content/drive/MyDrive/NLP/model1\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "def chat_with_model():\n",
        "  while True:\n",
        "    user_input = input(\"You: \")\n",
        "    input_ids = tokenizer.encode(user_input, return_tensors='pt')\n",
        "\n",
        "    response_ids = model.generate(input_ids, max_length=100, num_return_sequences=1,\n",
        "                                  temperature=0.9, top_k=20, do_sample=True,\n",
        "                                  pad_token_id=model.config.eos_token_id)\n",
        "\n",
        "    response = tokenizer.decode(response_ids[0], skip_special_tokens=True)\n",
        "    print(f\"Model: {response}\")\n",
        "\n",
        "chat_with_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}